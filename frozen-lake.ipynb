{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c5cf627e59564",
   "metadata": {},
   "source": [
    "# OpenAI Gym RL Environment Demo - Frozen Lake\n",
    "\n",
    "Frozen Lake involves a player navigating a grid world with the goal of reaching the goal state (G) from the start state (S) while avoiding holes/obstacles (H) that come along the way. \n",
    "\n",
    "The player can move in four directions: up, down, left, and right. \n",
    "The player receives a reward of 1 for reaching the goal state and a reward of 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1865acfc2566cc7",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "A type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives rewards for performing actions and aims to maximize the total reward over time.\n",
    "\n",
    "#### RL Terms\n",
    "\n",
    "- **Agent** → The decision maker that interacts with the environment\n",
    "- **Environment** → The space or system the agent operates in and responds to said agent’s actions\n",
    "- **State** → A representation of the environment’s current situation\n",
    "- **Action** → Choices the agent can make that affect the environment\n",
    "- **Reward** → A numerical value received after each action, indicating the desirability of the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200a1288f6966d9",
   "metadata": {},
   "source": [
    "#### Frozen Lake Example\n",
    "- **Agent** → Represents the player who is navigating the grid world\n",
    "- **Environment** → The 4x4 grid world\n",
    "- **State** → The player’s current position on the grid (Agent can be in 1 of the 16 positions or \"squares\" on the 4x4 grid)\n",
    "- **Action** → The player’s movement/direction in the grid (4 different actions per state -> up, down, left, right)\n",
    "- **Reward** → 1 for reaching the goal state (present), 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:27:29.445430Z",
     "start_time": "2024-11-14T13:27:29.428625Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "f57d58001556b368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:27:20.120567Z",
     "start_time": "2024-11-14T13:27:20.116713Z"
    }
   },
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True)"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "id": "72f9ff5e2d0ca432",
   "metadata": {},
   "source": [
    "Observation Space - The different states the agent can be in (16 possible states (4x4 grid, where agent is on one of the 16 squares)\n",
    "\n",
    "Action Space - The different actions the agent can take (Agent can do 4 possible actions: up, down, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "id": "179e7c9c89e3d852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:27:22.283928Z",
     "start_time": "2024-11-14T13:27:22.279919Z"
    }
   },
   "source": [
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "print(f\"Observation Space: {obs_space}\")\n",
    "print(f\"Action Space: {action_space}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Discrete(16)\n",
      "Action Space: Discrete(4)\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "2f41d3166c8a027c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:27:24.445286Z",
     "start_time": "2024-11-14T13:27:24.426912Z"
    }
   },
   "source": [
    "obs = env.reset()\n",
    "\n",
    "# The initial observation represents the starting state of the agent in the environment\n",
    "print(f\"Initial Observation: {obs[0]}\")\n",
    "\n",
    "env_screen_before = env.render(mode='rgb_array')\n",
    "\n",
    "# Agent completes a random action within the environment\n",
    "random_action = env.action_space.sample()\n",
    "\n",
    "# Get the updated observation space after the agent completes said random action\n",
    "new_obs, reward, done, truncated, info = env.step(random_action)\n",
    "print(f\"The new observation is {new_obs}\")\n",
    "\n",
    "env_screen_after = env.render(mode='rgb_array')\n",
    "\n",
    "env.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(env_screen_before)\n",
    "plt.title('Before')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(env_screen_after)\n",
    "plt.title('After')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Observation: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# The initial observation represents the starting state of the agent in the environment\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitial Observation: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m env_screen_before \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrgb_array\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Agent completes a random action within the environment\u001B[39;00m\n\u001B[1;32m      9\u001B[0m random_action \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39msample()\n",
      "\u001B[0;31mTypeError\u001B[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6ab6f-7e93-42bc-97e1-715116df6a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
